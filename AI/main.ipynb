{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflowjs as tfjs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7511</th>\n",
       "      <td>5</td>\n",
       "      <td>Two years back someone invited me to be the tu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7512</th>\n",
       "      <td>5</td>\n",
       "      <td>I had taken the responsibility to do something...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7513</th>\n",
       "      <td>1</td>\n",
       "      <td>I was at home and I heard a loud sound of spit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7514</th>\n",
       "      <td>6</td>\n",
       "      <td>I did not do the homework that the teacher had...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7515</th>\n",
       "      <td>1</td>\n",
       "      <td>I had shouted at my younger brother and he was...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     emotion                                           sentence\n",
       "7511       5  Two years back someone invited me to be the tu...\n",
       "7512       5  I had taken the responsibility to do something...\n",
       "7513       1  I was at home and I heard a loud sound of spit...\n",
       "7514       6  I did not do the homework that the teacher had...\n",
       "7515       1  I had shouted at my younger brother and he was..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainsplit = 7000\n",
    "emotionDict = {'joy': 0, 'fear': 1, 'anger': 2, 'sadness': 3, 'disgust': 4, 'shame': 5, 'guilt': 6}\n",
    "\n",
    "dataFrame = pd.read_csv('./ISEAR.csv')\n",
    "for i in range(len(dataFrame['emotion'])):\n",
    "    dataFrame['emotion'][i] = emotionDict[dataFrame['emotion'][i]]\n",
    "xTrain = dataFrame['sentence'][:trainsplit]\n",
    "yTrain = dataFrame['emotion'][:trainsplit]\n",
    "xTest = dataFrame['sentence'][trainsplit:]\n",
    "yTest = dataFrame['emotion'][:trainsplit]\n",
    "dataFrame.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\007ra\\Documents\\Codes\\AI-ML\\sentiment-analyzer\\AI\\main.ipynb Cell 3'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/007ra/Documents/Codes/AI-ML/sentiment-analyzer/AI/main.ipynb#ch0000002?line=0'>1</a>\u001b[0m tokenizer \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mpreprocessing\u001b[39m.\u001b[39mtext\u001b[39m.\u001b[39mTokenizer()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/007ra/Documents/Codes/AI-ML/sentiment-analyzer/AI/main.ipynb#ch0000002?line=1'>2</a>\u001b[0m tokenizer\u001b[39m.\u001b[39moov_token \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m<shobdobhandarErBahire>\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/007ra/Documents/Codes/AI-ML/sentiment-analyzer/AI/main.ipynb#ch0000002?line=2'>3</a>\u001b[0m tokenizer\u001b[39m.\u001b[39;49mfit_on_texts(xTrain)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/007ra/Documents/Codes/AI-ML/sentiment-analyzer/AI/main.ipynb#ch0000002?line=3'>4</a>\u001b[0m vocab \u001b[39m=\u001b[39m tokenizer\u001b[39m.\u001b[39mword_index\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/007ra/Documents/Codes/AI-ML/sentiment-analyzer/AI/main.ipynb#ch0000002?line=4'>5</a>\u001b[0m vocabSize \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(vocab)\n",
      "File \u001b[1;32m~\\.conda\\envs\\dataScience\\lib\\site-packages\\keras_preprocessing\\text.py:222\u001b[0m, in \u001b[0;36mTokenizer.fit_on_texts\u001b[1;34m(self, texts)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/007ra/.conda/envs/dataScience/lib/site-packages/keras_preprocessing/text.py?line=219'>220</a>\u001b[0m     seq \u001b[39m=\u001b[39m text\n\u001b[0;32m    <a href='file:///c%3A/Users/007ra/.conda/envs/dataScience/lib/site-packages/keras_preprocessing/text.py?line=220'>221</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/007ra/.conda/envs/dataScience/lib/site-packages/keras_preprocessing/text.py?line=221'>222</a>\u001b[0m     seq \u001b[39m=\u001b[39m text_to_word_sequence(text,\n\u001b[0;32m    <a href='file:///c%3A/Users/007ra/.conda/envs/dataScience/lib/site-packages/keras_preprocessing/text.py?line=222'>223</a>\u001b[0m                                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfilters,\n\u001b[0;32m    <a href='file:///c%3A/Users/007ra/.conda/envs/dataScience/lib/site-packages/keras_preprocessing/text.py?line=223'>224</a>\u001b[0m                                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlower,\n\u001b[0;32m    <a href='file:///c%3A/Users/007ra/.conda/envs/dataScience/lib/site-packages/keras_preprocessing/text.py?line=224'>225</a>\u001b[0m                                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msplit)\n\u001b[0;32m    <a href='file:///c%3A/Users/007ra/.conda/envs/dataScience/lib/site-packages/keras_preprocessing/text.py?line=225'>226</a>\u001b[0m \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m seq:\n\u001b[0;32m    <a href='file:///c%3A/Users/007ra/.conda/envs/dataScience/lib/site-packages/keras_preprocessing/text.py?line=226'>227</a>\u001b[0m     \u001b[39mif\u001b[39;00m w \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mword_counts:\n",
      "File \u001b[1;32m~\\.conda\\envs\\dataScience\\lib\\site-packages\\keras_preprocessing\\text.py:43\u001b[0m, in \u001b[0;36mtext_to_word_sequence\u001b[1;34m(text, filters, lower, split)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/007ra/.conda/envs/dataScience/lib/site-packages/keras_preprocessing/text.py?line=28'>29</a>\u001b[0m \u001b[39m\"\"\"Converts a text to a sequence of words (or tokens).\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/007ra/.conda/envs/dataScience/lib/site-packages/keras_preprocessing/text.py?line=29'>30</a>\u001b[0m \n\u001b[0;32m     <a href='file:///c%3A/Users/007ra/.conda/envs/dataScience/lib/site-packages/keras_preprocessing/text.py?line=30'>31</a>\u001b[0m \u001b[39m# Arguments\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/007ra/.conda/envs/dataScience/lib/site-packages/keras_preprocessing/text.py?line=39'>40</a>\u001b[0m \u001b[39m    A list of words (or tokens).\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/007ra/.conda/envs/dataScience/lib/site-packages/keras_preprocessing/text.py?line=40'>41</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/007ra/.conda/envs/dataScience/lib/site-packages/keras_preprocessing/text.py?line=41'>42</a>\u001b[0m \u001b[39mif\u001b[39;00m lower:\n\u001b[1;32m---> <a href='file:///c%3A/Users/007ra/.conda/envs/dataScience/lib/site-packages/keras_preprocessing/text.py?line=42'>43</a>\u001b[0m     text \u001b[39m=\u001b[39m text\u001b[39m.\u001b[39;49mlower()\n\u001b[0;32m     <a href='file:///c%3A/Users/007ra/.conda/envs/dataScience/lib/site-packages/keras_preprocessing/text.py?line=44'>45</a>\u001b[0m \u001b[39mif\u001b[39;00m sys\u001b[39m.\u001b[39mversion_info \u001b[39m<\u001b[39m (\u001b[39m3\u001b[39m,):\n\u001b[0;32m     <a href='file:///c%3A/Users/007ra/.conda/envs/dataScience/lib/site-packages/keras_preprocessing/text.py?line=45'>46</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(text, unicode):  \u001b[39m# noqa: F821\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "tokenizer.oov_token = '<shobdobhandarErBahire>'\n",
    "tokenizer.fit_on_texts(xTrain)\n",
    "vocab = tokenizer.word_index\n",
    "vocabSize = len(vocab)\n",
    "f = open('../src/stokenizer.json', 'w')\n",
    "f.write(json.dumps(vocab))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7000, 167), (7000, 7), 8796)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xTrain = tf.keras.preprocessing.sequence.pad_sequences(tokenizer.texts_to_sequences(dataFrame['sentence'][:trainsplit]))\n",
    "yTrain = tf.keras.utils.to_categorical((dataFrame['emotion'][:trainsplit]))\n",
    "xTest = tf.keras.preprocessing.sequence.pad_sequences(tokenizer.texts_to_sequences(dataFrame['sentence'][trainsplit:]))\n",
    "yTest = tf.keras.utils.to_categorical((dataFrame['emotion'][trainsplit:]))\n",
    "xTrain.shape, yTrain.shape, vocabSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocabSize, 64, input_length=167))\n",
    "model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)))\n",
    "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(7, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy' , optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "219/219 [==============================] - 9s 23ms/step - loss: 1.7926 - accuracy: 0.2729\n",
      "Epoch 2/15\n",
      "219/219 [==============================] - 5s 22ms/step - loss: 1.1645 - accuracy: 0.5780\n",
      "Epoch 3/15\n",
      "219/219 [==============================] - 6s 26ms/step - loss: 0.7774 - accuracy: 0.7399\n",
      "Epoch 4/15\n",
      "219/219 [==============================] - 7s 30ms/step - loss: 0.5135 - accuracy: 0.8329\n",
      "Epoch 5/15\n",
      "219/219 [==============================] - 6s 28ms/step - loss: 0.3726 - accuracy: 0.8830\n",
      "Epoch 6/15\n",
      "219/219 [==============================] - 7s 30ms/step - loss: 0.2580 - accuracy: 0.9216\n",
      "Epoch 7/15\n",
      "219/219 [==============================] - 8s 35ms/step - loss: 0.1900 - accuracy: 0.9394\n",
      "Epoch 8/15\n",
      "219/219 [==============================] - 6s 26ms/step - loss: 0.1626 - accuracy: 0.9509\n",
      "Epoch 9/15\n",
      "219/219 [==============================] - 5s 22ms/step - loss: 0.1329 - accuracy: 0.9611\n",
      "Epoch 10/15\n",
      "219/219 [==============================] - 4s 20ms/step - loss: 0.0983 - accuracy: 0.9723\n",
      "Epoch 11/15\n",
      "219/219 [==============================] - 4s 20ms/step - loss: 0.0910 - accuracy: 0.9747\n",
      "Epoch 12/15\n",
      "219/219 [==============================] - 5s 21ms/step - loss: 0.0703 - accuracy: 0.9793\n",
      "Epoch 13/15\n",
      "219/219 [==============================] - 4s 20ms/step - loss: 0.1003 - accuracy: 0.9703\n",
      "Epoch 14/15\n",
      "219/219 [==============================] - 4s 20ms/step - loss: 0.0756 - accuracy: 0.9767\n",
      "Epoch 15/15\n",
      "219/219 [==============================] - 4s 20ms/step - loss: 0.0508 - accuracy: 0.9857\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1be62665b20>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xTrain, yTrain, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 167) for input KerasTensor(type_spec=TensorSpec(shape=(None, 167), dtype=tf.float32, name='embedding_12_input'), name='embedding_12_input', description=\"created by layer 'embedding_12_input'\"), but it was called on an input with incompatible shape (None, 178).\n",
      "17/17 [==============================] - 1s 23ms/step - loss: 3.1705 - accuracy: 0.5484\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.1704599857330322, 0.5484496355056763]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(xTest, yTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    2  442    4 2420]] [[9.9966991e-01 2.2148837e-08 9.3392131e-08 1.4732043e-05 3.4667814e-08\n",
      "  3.1526538e-04 2.6533411e-09]] joy\n"
     ]
    }
   ],
   "source": [
    "inpt = input('enter the text')\n",
    "text = tf.keras.preprocessing.sequence.pad_sequences(tokenizer.texts_to_sequences([inpt]), padding='pre', maxlen=66)\n",
    "dictEmotion = {0: 'joy', 1: 'fear', 2: 'anger', 3: 'sadness', 4: 'disgust', 5: 'shame' , 6: 'guilt'}\n",
    "\n",
    "print(text, model.predict(text), dictEmotion[np.argmax(model.predict(text))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfjs.converters.save_keras_model(model, '../public/model')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e38c6d658e3c4e97a4d48d96dcbbb50367a88e38ba291af5da90eb5fcad12b1b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('dataScience')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
